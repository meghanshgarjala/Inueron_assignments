{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390c4fa4-8657-4ce7-999a-c663f2a07dc5",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\r\n",
    "represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421b161-9519-410f-a090-9fca7df4a43c",
   "metadata": {},
   "source": [
    "Definition: R-squared (R¬≤) is a statistical measure that evaluates the goodness of fit of a linear regression model. It represents the proportion of variance in the dependent variable (y) that is explained by the independent variable(s) (x).\r\n",
    "\r\n",
    "Formula: R¬≤ = 1 - (SSres / SStot), where:\r\n",
    "\r\n",
    "SSres is the sum of squared residuals (err\n",
    "ors)\r\n",
    "SStot is the total sum of squares (variance \n",
    "in y)\r\n",
    "Interpretation: R¬≤ values range from 0 to 1, where:\r\n",
    "\r\n",
    "0 indicates that the independent variable(s) do not explain any variance in the dependent \n",
    "variable\r\n",
    "1 indicates that the independent variable(s) perfectly explain the variance in the dependent\n",
    " variable\r\n",
    "Values between 0 and 1 indicate the proportion of variance explained by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b71c52-953d-4373-961a-c541b4c86eb1",
   "metadata": {},
   "source": [
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b1d8c-2ccb-4863-bb0d-55665ff5080b",
   "metadata": {},
   "source": [
    "Adjusted R-squared, also known as Adjusted R2, is a modified version of the traditional R-squared (R2) metric used in regression analysis. It is designed to penalize models with too many independent variables (predictors) and provide a more accurate estimate of the model‚Äôs goodness of fit.\r\n",
    "\r\n",
    "Regular R-squared (R:)\r\n",
    "\r\n",
    "R2 measures the proportion of the variance in the dependent variable that is explained by the independent variables. It is calculated as 1 - (Sum of Squared Residuals (SSR) / Total Sum of Squares (SST)). While R2 provides an initial assessment of model fit, it has a limitation: it increases as more independent variables are added to the model, even if those variables are irrelevant or noisy. This can lead to overfitting, where the model becomes too complex and performs poorly on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b63109-25fb-4073-bff6-a767e2d30c0b",
   "metadata": {},
   "source": [
    "Q3. When is it more appropriate to use adjusted R-squared?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5bfa80-05cf-4234-acc5-5e9b7e32f38a",
   "metadata": {},
   "source": [
    "Use Adjusted R-squared: It is more appropriate when comparing models with a different number of predictors. It helps prevent overestimating the explanatory power of the model by accounting for the number of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9198ab-42b4-4201-afc4-abd99ab9e829",
   "metadata": {},
   "source": [
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\r\n",
    "calculated, and what do they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726197e8-d21c-4dbc-9b1a-06dae90a7af7",
   "metadata": {},
   "source": [
    "In the context of regression analysis, RMSE (Root Mean Squared Error), MSE (Mean Squared Error), and MAE (Mean Absolute Error) are three essential metrics used to evaluate the performance of a model.\r\n",
    "\r\n",
    "MSE (Mean Squared Error): MSE is the average of the squared differences between the original and predicted values. It‚Äôs calculated as:\r\n",
    "\r\n",
    "MSE = (1/n) * Œ£(y_true - y_pred)^2\r\n",
    "\r\n",
    "where n is the number of samples, y_true is the actual value, and y_pred is the predicted value. MSE represents the average magnitude of the errors. A lower MSE indicates better model performance.\r\n",
    "\r\n",
    "RMSE (Root Mean Squared Error): RMSE is the square root of MSE, providing a measure of the average magnitude of the errors in the same units as the target variable. It‚Äôs calculated as:\r\n",
    "\r\n",
    "RMSE = ‚àö(MSE)\r\n",
    "\r\n",
    "RMSE is more interpretable than MSE, especially when dealing with large datasets, as it provides a sense of the typical error magnitude.\r\n",
    "\r\n",
    "MAE (Mean Absolute Error): MAE is the average of the absolute differences between the original and predicted values. It‚Äôs calculated as:\r\n",
    "\r\n",
    "MAE = (1/n) * Œ£|y_true - y_pred|\r\n",
    "\r\n",
    "MAE is less sensitive to outliers than MSE and RMSE, as it doesn‚Äôt square the errors. A lower MAE indicates better model performance.\r\n",
    "\r\n",
    "These metrics are used to identify areas where the model is performing poorly and make adjustments to improve the accuracy of predictions. In business contexts, MAE can be used to evaluate the accuracy of sales forecasting models and energy demand forecasting, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8d4aba-2b33-4cf8-9f61-ee8b4c383110",
   "metadata": {},
   "source": [
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\r\n",
    "regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec8cb7-3c14-4c24-9615-30f986710a14",
   "metadata": {},
   "source": [
    "#RMSE:\n",
    "\n",
    "Advantages: Sensitive to large errors, providing a useful metric for models where large errors are particularly undesirable.\n",
    "\n",
    "Disadvantages: Can be heavily influenced by outliers due to squaring the errors.\n",
    "\n",
    "#MSE:\n",
    "\n",
    "Advantages: Similar to RMSE, useful for mathematical analysis and optimization.\n",
    "\n",
    "Disadvantages: Like RMSE, sensitive to outliers and not in the same units as the response variable.\n",
    "\n",
    "#MAE:\n",
    "\n",
    "Advantages: Less sensitive to outliers, providing a more robust measure of average model performance.\n",
    "\n",
    "Disadvantages: Does not penalize larger errors as heavily as MSE or RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46bdce1-852b-4db8-aa11-ce2817708603",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\r\n",
    "it more appropriate to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0933cd2f-8645-442c-8d30-27c8094939fe",
   "metadata": {},
   "source": [
    "Lasso Regularization:\n",
    "\n",
    "Definition: Lasso (Least Absolute Shrinkage and Selection Operator) adds a penalty equal to the absolute value of the magnitude of coefficients to the loss function, encouraging sparse solutions.\n",
    "\n",
    "Equation:\n",
    "Lasso¬†Cost¬†Function=  RSS+ùúÜ*‚àë ùëó=1 ùëù *‚à£ùõΩùëó‚à£\n",
    "\n",
    "Difference from Ridge Regularization:\n",
    "\n",
    "Ridge Regularization: Adds a penalty equal to the squared magnitude of coefficients.\n",
    "\n",
    "Lasso Regularization: Can set some coefficients exactly to zero, effectively performing feature selection.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ed5b4-2931-437d-82ed-4e270e207e37",
   "metadata": {},
   "source": [
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\r\n",
    "example to illustrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e203901d-47bc-424e-b2de-3055d6f8230f",
   "metadata": {},
   "source": [
    "Regularized Linear Models:\n",
    "\n",
    "Preventing Overfitting: Regularization adds a penalty to the loss function to constrain the magnitude of the coefficients, discouraging overly complex models.\n",
    "\n",
    "Example: In a high-dimensional dataset, Ridge or Lasso regression can reduce the risk of overfitting by penalizing large coefficients, thereby simplifying the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbccd82-67d8-4d14-851a-8e28f6697f1a",
   "metadata": {},
   "source": [
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\r\n",
    "choice for regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ebe607-95c3-4e35-bda5-ddc74311466a",
   "metadata": {},
   "source": [
    "Limitations:\n",
    "\n",
    "Data Requirements: Regularized models may not perform well with small datasets as the penalty can dominate the loss function.\n",
    "\n",
    "Interpretability: The introduction of a penalty term can make the model harder to interpret.\n",
    "\n",
    "Choice of Regularization Parameter: The effectiveness of regularization depends on choosing an appropriate value for the regularization parameter (ùúÜ), which can be challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8273065-a223-494b-9072-8308257c3f01",
   "metadata": {},
   "source": [
    "Q9. You are comparing the performance of two regression models using different evaluation metrics.\r\n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\r\n",
    "performer, and why? Are there any limitations to your choice of metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03258964-4eda-455b-8645-f0fd940a2bd2",
   "metadata": {},
   "source": [
    "Comparison:\n",
    "\n",
    "Model A (RMSE = 10): Suggests average prediction error of 10 units.\n",
    "Model B (MAE = 8): Suggests average absolute prediction error of 8 units.\n",
    "\n",
    "Choice:\n",
    "\n",
    "Model B (MAE = 8) might be chosen as it indicates a lower average error. However, this choice depends on the context:\n",
    "If minimizing large errors is more important, RMSE should be considered.\n",
    "If robustness to outliers is preferred, MAE is a better metric.\n",
    "\n",
    "Limitations:\n",
    "\n",
    "Different metrics focus on different aspects of model performance, so the choice should align with the specific goals and requirements of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e363b59c-2dae-48ea-a028-753825d47e1a",
   "metadata": {},
   "source": [
    "Q10. You are comparing the performance of two regularized linear models using different types of\r\n",
    "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\r\n",
    "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\r\n",
    "better performer, and why? Are there any trade-offs or limitations to your choice of regularization\r\n",
    "method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9aa247-5e83-4302-8793-96adc8bce456",
   "metadata": {},
   "source": [
    "Comparison:\n",
    "\n",
    "Model A (Ridge, Œª=0.1): Ridge regularization tends to shrink coefficients but does not set any to zero.\n",
    "\n",
    "Model B (Lasso, Œª=0.5): Lasso regularization can shrink some coefficients to zero, performing feature selection.\n",
    "\n",
    "Choice:\n",
    "\n",
    "#Depends on the Goal:\n",
    "\n",
    "If the primary goal is to reduce model complexity and select important features, Model B (Lasso) might be better.\n",
    "\n",
    "If the focus is on minimizing prediction error without reducing the number of features, Model A (Ridge) might be preferable.\n",
    "\n",
    "#Trade-offs:\n",
    "\n",
    "Ridge: Tends to be better when dealing with multicollinearity.\n",
    "\n",
    "Lasso: Useful for feature selection but might exclude relevant features if Œª is too high.\n",
    "\n",
    "#Limitations:\n",
    "\n",
    "The choice of regularization method and parameter ùúÜ significantly impacts model performance and interpretability, requiring careful consideration and validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
